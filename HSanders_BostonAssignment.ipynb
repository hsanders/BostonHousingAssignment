{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Assignment\n",
    "\n",
    "In this assignment you'll be using linear regression to estimate the cost of house in boston, using a well known dataset.\n",
    "\n",
    "Goals:\n",
    "+  Measure the performance of the model I created using $R^{2}$ and MSE\n",
    "> Learn how to use sklearn.metrics.r2_score and sklearn.metrics.mean_squared_error\n",
    "+  Implement a new model using L2 regularization\n",
    "> Use sklearn.linear_model.Ridge or sklearn.linear_model.Lasso \n",
    "+  Get the best model you can by optimizing the regularization parameter.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bean = datasets.load_boston()\n",
    "print bean.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_boston():\n",
    "    scaler = StandardScaler()\n",
    "    boston = datasets.load_boston()\n",
    "    X=boston.data\n",
    "    y=boston.target\n",
    "    X = scaler.fit_transform(X)\n",
    "    return train_test_split(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379L, 13L)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Linear Regression\n",
    "\n",
    "It's as easy as instantiating a new regression object (line 1) and giving your regression object your training data\n",
    "(line 2) by calling .fit(independent variables, dependent variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction\n",
    "X_test is our holdout set of data.  We know the answer (y_test) but the computer does not.   \n",
    "\n",
    "Using the command below, I create a tuple for each observation, where I'm combining the real value (y_test) with\n",
    "the value our regressor predicts (clf.predict(X_test))\n",
    "\n",
    "Use a similiar format to get your r2 and mse metrics working.  Using the [scikit learn api](http://scikit-learn.org/stable/modules/model_evaluation.html) if you need help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19.100000000000001, 16.689455476234855),\n",
       " (22.5, 18.00387192198135),\n",
       " (27.100000000000001, 27.664138041661296),\n",
       " (22.699999999999999, 21.869041894915917),\n",
       " (24.100000000000001, 20.884018522847377),\n",
       " (29.600000000000001, 24.625122881343263),\n",
       " (21.199999999999999, 23.157707925045219),\n",
       " (34.899999999999999, 33.700968178389779),\n",
       " (12.1, 17.635214637911432),\n",
       " (20.100000000000001, 15.811584290271346),\n",
       " (32.0, 33.250990144419887),\n",
       " (13.800000000000001, 16.211620231701076),\n",
       " (17.300000000000001, 16.408679610704663),\n",
       " (16.600000000000001, 15.335230832988135),\n",
       " (18.800000000000001, 20.69190527919412),\n",
       " (27.5, 31.819358543720959),\n",
       " (16.100000000000001, 18.062591602622529),\n",
       " (32.700000000000003, 30.344374712096226),\n",
       " (17.800000000000001, 21.559146670648275),\n",
       " (18.5, 19.463003197290025),\n",
       " (19.899999999999999, 18.47419281752461),\n",
       " (13.9, 13.44266892373671),\n",
       " (30.300000000000001, 33.054338295064646),\n",
       " (7.0, 8.4152248712337769),\n",
       " (19.600000000000001, 18.925147149479834),\n",
       " (19.100000000000001, 19.279747397732589),\n",
       " (17.0, 22.930998442583999),\n",
       " (15.6, 12.797186358280014),\n",
       " (27.899999999999999, 19.616293737293976),\n",
       " (21.800000000000001, 20.503435469213176),\n",
       " (23.0, 19.572868470486494),\n",
       " (21.399999999999999, 24.575734790463741),\n",
       " (33.100000000000001, 32.691824742117745),\n",
       " (13.1, 14.771986002642096),\n",
       " (19.300000000000001, 17.38492276345027),\n",
       " (15.699999999999999, 14.763357059104372),\n",
       " (13.800000000000001, 12.769720490813418),\n",
       " (19.300000000000001, 20.8574597696004),\n",
       " (15.0, 19.459556016552746),\n",
       " (23.699999999999999, 26.384777575421545),\n",
       " (24.300000000000001, 29.287913193681096),\n",
       " (23.100000000000001, 24.589598982882688),\n",
       " (8.8000000000000007, 3.6540090101924534),\n",
       " (19.399999999999999, 25.895587068873496),\n",
       " (20.300000000000001, 22.536068684326665),\n",
       " (23.399999999999999, 24.074246161282463),\n",
       " (24.699999999999999, 22.810790167271307),\n",
       " (17.199999999999999, 13.458359769698713),\n",
       " (27.0, 33.026180554294776),\n",
       " (20.5, 19.998223625714949),\n",
       " (31.600000000000001, 33.238510721355595),\n",
       " (50.0, 24.243799970000936),\n",
       " (11.300000000000001, 13.125211543934864),\n",
       " (13.5, 13.583276671678599),\n",
       " (24.699999999999999, 24.800872253091015),\n",
       " (22.199999999999999, 22.042899257119565),\n",
       " (15.4, 17.435530681912461),\n",
       " (18.699999999999999, 18.018217515702673),\n",
       " (50.0, 33.61631893817831),\n",
       " (29.800000000000001, 24.783736345983385),\n",
       " (27.100000000000001, 20.01001088556157),\n",
       " (12.300000000000001, 12.765493371914067),\n",
       " (46.700000000000003, 34.805514858247903),\n",
       " (33.299999999999997, 36.351099353642674),\n",
       " (35.200000000000003, 34.83912737986563),\n",
       " (23.300000000000001, 21.85247997655793),\n",
       " (16.600000000000001, 18.255635652522216),\n",
       " (27.5, 23.833365166496943),\n",
       " (22.600000000000001, 22.765606735717046),\n",
       " (23.899999999999999, 26.74994633585144),\n",
       " (26.399999999999999, 22.721933689517112),\n",
       " (46.0, 40.158461622272618),\n",
       " (15.0, 15.309581383089949),\n",
       " (15.6, 16.683153244915147),\n",
       " (19.300000000000001, 22.393314927028943),\n",
       " (8.3000000000000007, 10.109887903041656),\n",
       " (22.600000000000001, 18.771585185226751),\n",
       " (31.699999999999999, 32.695473841153614),\n",
       " (21.800000000000001, 20.910560662160172),\n",
       " (50.0, 42.472561773726753),\n",
       " (15.1, 16.83997665939533),\n",
       " (11.699999999999999, 14.900139697992074),\n",
       " (23.699999999999999, 27.692025269798947),\n",
       " (26.600000000000001, 27.497907019483925),\n",
       " (12.0, 11.444684403140005),\n",
       " (13.199999999999999, 8.8709375901215317),\n",
       " (13.300000000000001, 15.734370242527106),\n",
       " (8.6999999999999993, 8.938547739102475),\n",
       " (10.4, 7.1410287899677822),\n",
       " (10.800000000000001, 11.386561728186644),\n",
       " (35.399999999999999, 34.324128404162089),\n",
       " (31.199999999999999, 28.384791639942833),\n",
       " (23.899999999999999, 26.657224333210237),\n",
       " (22.0, 27.711165191025728),\n",
       " (22.399999999999999, 22.910843631211009),\n",
       " (20.600000000000001, 21.889797055199185),\n",
       " (19.600000000000001, 17.377265699737489),\n",
       " (19.800000000000001, 18.506018100698093),\n",
       " (24.699999999999999, 25.103115227631609),\n",
       " (13.6, 12.420185725121408),\n",
       " (20.5, 24.292089518836342),\n",
       " (39.799999999999997, 33.822674711113557),\n",
       " (22.100000000000001, 26.673391814278322),\n",
       " (15.6, 21.027644226767169),\n",
       " (22.199999999999999, 24.399797483393272),\n",
       " (14.9, 15.182372575073304),\n",
       " (18.399999999999999, 15.525526635749037),\n",
       " (19.699999999999999, 21.714213327859817),\n",
       " (18.600000000000001, 19.640472547203288),\n",
       " (10.5, 12.3705434514758),\n",
       " (13.5, 13.128796575610153),\n",
       " (20.600000000000001, 16.702368932593604),\n",
       " (20.0, 20.709341808678026),\n",
       " (20.600000000000001, 21.988736521856914),\n",
       " (21.5, 21.20562243547343),\n",
       " (24.300000000000001, 24.500723887245694),\n",
       " (20.100000000000001, 20.870819280607282),\n",
       " (14.6, 18.675250375825886),\n",
       " (50.0, 38.602278300199501),\n",
       " (19.899999999999999, 19.118061779750189),\n",
       " (20.100000000000001, 18.318953329182783),\n",
       " (50.0, 40.40182611070621),\n",
       " (24.600000000000001, 29.01917748614143),\n",
       " (32.5, 30.531447803491453),\n",
       " (15.199999999999999, 11.929281425628471),\n",
       " (16.199999999999999, 14.926253688690327),\n",
       " (8.5, 15.934220259880355)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip (y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Making a Prediction:  R^2 (coefficient and determination) regression score function\n",
    "Using R2 to determine how well the data fits the model.  The goal is to be as close to 1 as possible (1 being that the data fits the model perfectly and 0 being that the data does not fit the model at all).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "#import Lasso\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75453347189497411"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Coefficient of Determination seems to indicate that the model fits the data well with a number of 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73420547407869918"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying a different alpha\n",
    "alpha = 0.2\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase in alpha brought our Coefficient of Determination farther away from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758942529151996"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying a decrease in alpha\n",
    "alpha = 0.08\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76273282129931486"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying a decrease in alpha\n",
    "alpha = 0.06\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76591016979004933"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying a decrease in alpha\n",
    "alpha = 0.04\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76843526759152736"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying a decrease in alpha\n",
    "alpha = 0.02\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7695598523708822"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying a decrease in alpha\n",
    "alpha = 0.008\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making our alpha smaller does get us closer to 1, but it is not a significant change from the original alpha of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction:  RMSE (Root Mean Square Error) \n",
    "<a href=https://upload.wikimedia.org/math/1/7/3/173e0dd312ace976dbc640af8f9014b8.png><img border=\"0\" alt=\"Wiki\" src=\"https://upload.wikimedia.org/math/1/7/3/173e0dd312ace976dbc640af8f9014b8.png\" width=\"300\"> </a>\n",
    "\n",
    "Root Mean Square Error is a way to test a linear model to see if it's good, or not. RMSE is calculated by taking the squared average differences of each prediction and then getting the square root to get a positive number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#import math\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.386605689364285"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate and display RMSE\n",
    "math.sqrt(mean_squared_error(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dependent variable range is from 7 to 50, I would conclude that 4.34 isn't a terrible RMSE value, although I would like to see it a little smaller.  According to The Analysis Factor (http://www.theanalysisfactor.com/assessing-the-fit-of-regression-models/), RMSE is an absolute measure of fit that shows how accurately the model predicts the response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
